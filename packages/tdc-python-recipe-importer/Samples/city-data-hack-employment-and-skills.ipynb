{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Employment and Skills\n",
    "\n",
    "This notebook demonstrates the use of the Python recipe wrapper to create a basic data pack that you can use to get you started with the GLA challenge of Employment and Skills. If you want to know more on the Challenge you can visit our [Tombolo website](http://www.tombolo.org.uk/greater-london-authority/). Don't forget that you can use the [City Data Explorer](https://tombolo-staging.emu-analytics.net) web app to visualise and style your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Background\n",
    "\n",
    "**The Tombolo project** is a Future Cities Catapult project funded by InnovateUK. It is a research and development project focused on understanding the value of data to unlock the potential of our cities. A big part of the Tombolo project is  the [Digital Connector](http://www.tombolo.org.uk/products/), an open source piece of software for Data Scientists to import and combine datasets into a standard format and model. You can visit the project on [Github](https://github.com/FutureCitiesCatapult/TomboloDigitalConnector) to learn some background as well as instructions on how to use it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal\n",
    "\n",
    "We will use the Python recipe implementation to tell Digital Connector to fetch some Social Isolation data for Barking and dagenham.\n",
    "\n",
    "The geographical unit of measurement for our exports (the ***Subject*** in DC language) will be the Local Super Output Area (LSOA).\n",
    "\n",
    "The data that we will be fetching are:\n",
    "* ONS data on employment/unemployment\n",
    "* ONS data on Business Demography\n",
    "* Data on employment seekers allowance\n",
    "* Data on Gross Annual Income\n",
    "\n",
    "**Please note that the above datasources are only indicative! You should think more holistic in order to tackle this challenge!**\n",
    "\n",
    "Our output will be a GeoJson file GLA's local authorities along with the attributes of interest. Feel free to play around with the code, explore the DC and download more resources that will help you tackle the Challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets get started\n",
    "\n",
    "First, we import some libraries that we will be using as well as the recipe.py file\n",
    "that contains all the classes necessary to build our recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "home_dir = str(Path.home())\n",
    "tdc = os.path.join(home_dir, 'Desktop/python_library_dc/digital-connector-python')\n",
    "digital_connector = os.path.join(home_dir, 'Desktop/UptodateProject/TomboloDigitalConnector')\n",
    "os.chdir(tdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recipe import Recipe, Subject, Dataset, Geo_Match_Rule, Match_Rule, Datasource, GeographicAggregationField, FixedValueField, AttributeMatcherField, AttributeMatcher, LatestValueField, MapToContainingSubjectField, BackOffField, PercentilesField, LinearCombinationField"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is to create a **Subject**. This represents the core geometry on which all our operations will be based on. It also specifies the export geometry of our final geojson file. We are using *localAuthority* and a **match_rule** to filter out all local authorities not belonging to Greater London Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_geometry = Subject(subject_type_label='localAuthority', provider_label='uk.gov.ons', \n",
    "                           match_rule=Match_Rule(attribute_to_match_on='label', pattern='E0900%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define our **Datasource**. This will tell DC what data to download. For more information on DC importers and datasource_id's consult the [catalogue.json](https://github.com/FutureCitiesCatapult/TomboloDigitalConnector/blob/master/src/main/resources/catalogue.json) or use the terminal \n",
    "\n",
    "**gradle info -Pi= *name_of_the_class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "localAuthority = Datasource(importer_class='uk.org.tombolo.importer.ons.OaImporter',\n",
    "                            datasource_id='localAuthority')\n",
    "\n",
    "englandGeneralisedBoundaries = Datasource(importer_class='uk.org.tombolo.importer.ons.OaImporter' ,\n",
    "                                          datasource_id='englandBoundaries')\n",
    "\n",
    "NOMISIncome = Datasource(datasource_id='ONSGrossAnnualIncome',\n",
    "                         importer_class='uk.org.tombolo.importer.ons.ONSEmploymentImporter')\n",
    "\n",
    "ONSBusiness = Datasource(datasource_id='ONSBusiness',\n",
    "                        importer_class='uk.org.tombolo.importer.ons.ONSBusinessDemographyImporter')\n",
    "\n",
    "NOMISJobs = Datasource(datasource_id='ONSJobsDensity',\n",
    "                      importer_class='uk.org.tombolo.importer.ons.ONSEmploymentImporter')\n",
    "\n",
    "NOMISEmployment = Datasource(datasource_id='APSEmploymentRate',\n",
    "                            importer_class='uk.org.tombolo.importer.ons.ONSEmploymentImporter')\n",
    "\n",
    "NOMISUnEmployment = Datasource(datasource_id='APSUnemploymentRate',\n",
    "                            importer_class='uk.org.tombolo.importer.ons.ONSEmploymentImporter')\n",
    "\n",
    "NOMISBenefits = Datasource(datasource_id='ESAclaimants',\n",
    "                          importer_class='uk.org.tombolo.importer.ons.ONSEmploymentImporter')\n",
    "\n",
    "PopulationDensity = Datasource(datasource_id='qs102ew', \n",
    "                              importer_class='uk.org.tombolo.importer.ons.CensusImporter')\n",
    "\n",
    "\n",
    "importers_list = [localAuthority,englandGeneralisedBoundaries, NOMISIncome, ONSBusiness, NOMISJobs,\n",
    "                  NOMISEmployment, NOMISUnEmployment,NOMISBenefits, PopulationDensity]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we defined the datasources we need to tell the DC which attributes to fetch from the database. To do that we create **AttributeMatcher** fields for all the attributes of interest. Having specified the attributes that we will be using, we now need to use them within DC's **Fields**. There are numerous fields each one with its own unique properties. Please consult [DC's github repo](https://github.com/FutureCitiesCatapult/TomboloDigitalConnector/blob/master/documentation/fields-and-models.md) for more information on fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed Successfully!!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Fields ###\n",
    "\n",
    "### Defining our attributes and passing them to fields ###\n",
    "\n",
    "### Unemployment \n",
    "\n",
    "unemployment_attribute = AttributeMatcher(label='APSUnemploymentRate',\n",
    "                                                   provider='uk.gov.ons')\n",
    "unemployment = LatestValueField(attribute_matcher=unemployment_attribute,\n",
    "                                                label='APSUnemploymentRate')\n",
    "\n",
    "### Employment \n",
    "\n",
    "employment_attribute = AttributeMatcher(label='APSEmploymentRate',\n",
    "                                                   provider='uk.gov.ons')\n",
    "employment = LatestValueField(attribute_matcher=employment_attribute,\n",
    "                                                label='APSEmploymentRate')\n",
    "\n",
    "### Claiming allowance \n",
    "\n",
    "claimants_attribute = AttributeMatcher(label='ESAclaimants',\n",
    "                                                   provider='uk.gov.ons')\n",
    "claimants = LatestValueField(attribute_matcher=claimants_attribute,\n",
    "                                                label='ESAclaimants')\n",
    "\n",
    "\n",
    "### Tranforming them to percentiles after taking care of the missing values ###\n",
    "\n",
    "fields = ['unemployment','employment', 'claimants']\n",
    "\n",
    "f={}\n",
    "for i in fields:\n",
    "    f['geo_{0}'.format(i)] = GeographicAggregationField(subject=subject_geometry,\n",
    "                                                           field=eval(('{0}').format(i)),\n",
    "                                                           function='mean',\n",
    "                                                           label='geo_{0}'.format(i))\n",
    "\n",
    "\n",
    "    f['map_{0}'.format(i)] = MapToContainingSubjectField(field=f['geo_{0}'.format(i)],\n",
    "                                                                   subject=Subject(subject_type_label='englandBoundaries',\n",
    "                                                                                  provider_label='uk.gov.ons'),\n",
    "                                                                   label='map_{0}'.format(i))\n",
    "\n",
    "    f['backoff_{0}'.format(i)] = BackOffField(fields=[eval(('{0}').format(i)),\n",
    "                                                             f['map_{0}'.format(i)]],\n",
    "                                         label='backoff_{0}'.format(i))\n",
    "    if i == 'employment':\n",
    "        f['percentile_{0}'.format(i)] = PercentilesField(field=f['backoff_{0}'.format(i)],\n",
    "                                                         inverse=False,\n",
    "                                                         percentile_count=10,\n",
    "                                                         normalization_subjects=[subject_geometry],\n",
    "                                                         label='percentile_{0}'.format(i))\n",
    "    else:\n",
    "        f['percentile_{0}'.format(i)] = PercentilesField(field=f['backoff_{0}'.format(i)],\n",
    "                                                         inverse=True,\n",
    "                                                         percentile_count=10,\n",
    "                                                         normalization_subjects=[subject_geometry],\n",
    "                                                         label='percentile_{0}'.format(i))        \n",
    "\n",
    "\n",
    "### Combining the resulting fields with a LinearCombinationField and convering the result to percentiles ###\n",
    "\n",
    "combined_employment = LinearCombinationField(fields=[f['percentile_claimants'],\n",
    "                                                 f['percentile_employment'],\n",
    "                                                 f['percentile_unemployment']],\n",
    "                                         scalars = [1.,1.,1.],\n",
    "                                         label='Unemployment lower than the East London average')\n",
    "\n",
    "percentile_combined_employment = PercentilesField(field=combined_employment,\n",
    "                                                     inverse=False,\n",
    "                                                     label='unemployment',\n",
    "                                                     percentile_count=10,\n",
    "                                                     normalization_subjects=[subject_geometry])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are in a good shape to run our recipe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Run the exporter and plot the result ###\n",
    "\n",
    "importers = [localAuthority,englandGeneralisedBoundaries,\n",
    "            NOMISEmployment,NOMISUnEmployment,NOMISBenefits]\n",
    "\n",
    "dataset = Dataset(subjects=[subject_geometry], fields=[f['percentile_claimants'], \n",
    "                                                       f['percentile_employment'], f['percentile_unemployment']],\n",
    "                  datasources=importers)\n",
    "\n",
    "recipe = Recipe(dataset,timestamp=False)\n",
    "recipe.build_recipe(console_print=False)\n",
    "\n",
    "recipe.run_recipe(tombolo_path=digital_connector,\n",
    "                  output_path = 'Desktop/employment_and_skills.json', console_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets view the results using geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>percentile_employment</th>\n",
       "      <th>label</th>\n",
       "      <th>percentile_unemployment</th>\n",
       "      <th>percentile_claimants</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>POLYGON ((-0.0968 51.5233, -0.0964 51.5228, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(POLYGON ((0.1482 51.5968, 0.1481 51.5964, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>POLYGON ((-0.199 51.6682, -0.1966 51.6681, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(POLYGON ((0.1439 51.5077, 0.1475 51.5066, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>POLYGON ((-0.2671 51.6004, -0.2597 51.5942, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  percentile_employment      label  \\\n",
       "0        City of London                    4.0  E09000001   \n",
       "1  Barking and Dagenham                    1.0  E09000002   \n",
       "2                Barnet                    4.0  E09000003   \n",
       "3                Bexley                    5.0  E09000004   \n",
       "4                 Brent                    2.0  E09000005   \n",
       "\n",
       "   percentile_unemployment  percentile_claimants  \\\n",
       "0                      6.0                  10.0   \n",
       "1                      1.0                   6.0   \n",
       "2                     10.0                   4.0   \n",
       "3                      8.0                   8.0   \n",
       "4                      3.0                   3.0   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-0.0968 51.5233, -0.0964 51.5228, -0...  \n",
       "1  (POLYGON ((0.1482 51.5968, 0.1481 51.5964, 0.1...  \n",
       "2  POLYGON ((-0.199 51.6682, -0.1966 51.6681, -0....  \n",
       "3  (POLYGON ((0.1439 51.5077, 0.1475 51.5066, 0.1...  \n",
       "4  POLYGON ((-0.2671 51.6004, -0.2597 51.5942, -0...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gpd.read_file(home_dir + '/Desktop/employment_and_skills.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
